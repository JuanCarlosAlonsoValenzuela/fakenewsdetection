{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search (Optimización de Hiperparámetros)\n",
    "A la hora de crear modelos en el mundo del Machine Learning, es necesario seleccionar varios hiperparámetros, como el ratio de Dropout y el learning rate. La elección de los valores de estos hiperparámetros tienen repercusiones directas en las métricas que evaluan el rendimiento del modelo, como f1-score. Por lo tanto, un paso imprescindible en el proceso de entrenamiento de un modelo consiste en identificar los mejores hiperparámetros para el problema, que deben obtenerse mediante experimentación. Este proceso se conoce como Optimización de Hiperparámetros o, en inglés, \"Hyperparameter Tuning\". <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Juan\n",
      "[nltk_data]     Carlos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer as tf_tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "import nlp_functions as nlp_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset en memoria\n",
    "df = pd.read_csv('../../dataset/ticnn_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['donald', 'trump', 'property', 'showcase', 'b...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['trump', 'foundation', 'tell', 'new', 'york',...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['donald', 'trump', 'prepares', 'white', 'hous...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['lure', 'chinese', 'investor', 'trump', 'name...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['melania', 'barron', 'trump', 'wont', 'immedi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  type\n",
       "0  ['donald', 'trump', 'property', 'showcase', 'b...   0.0\n",
       "1  ['trump', 'foundation', 'tell', 'new', 'york',...   0.0\n",
       "2  ['donald', 'trump', 'prepares', 'white', 'hous...   0.0\n",
       "3  ['lure', 'chinese', 'investor', 'trump', 'name...   0.0\n",
       "4  ['melania', 'barron', 'trump', 'wont', 'immedi...   0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteración del orden\n",
    "df = df.sample(frac = 1., random_state = 1)\n",
    "\n",
    "# Transformamos la columna text a lista de string\n",
    "from ast import literal_eval\n",
    "df['text'] = df['text'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11690</th>\n",
       "      <td>[rwanda, philippine, rate, well, uk, gender, e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16702</th>\n",
       "      <td>[climate, change, opinion, susan, goldberg, ed...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19393</th>\n",
       "      <td>[inside, bernie, sander, unorthodox, debate, p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>[school, america, close, election, day, due, f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>[trump, portray, clinton, hypocrite, recount, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  type\n",
       "11690  [rwanda, philippine, rate, well, uk, gender, e...   1.0\n",
       "16702  [climate, change, opinion, susan, goldberg, ed...   0.0\n",
       "19393  [inside, bernie, sander, unorthodox, debate, p...   0.0\n",
       "7374   [school, america, close, election, day, due, f...   1.0\n",
       "3874   [trump, portray, clinton, hypocrite, recount, ...   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string(input):\n",
    "  res = ''\n",
    "  for word in input:\n",
    "    res = res + ' ' + word \n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función convert_to_string a los textos\n",
    "df['text'] = df['text'].apply(convert_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11690</th>\n",
       "      <td>rwanda philippine rate well uk gender equalit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16702</th>\n",
       "      <td>climate change opinion susan goldberg editor ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19393</th>\n",
       "      <td>inside bernie sander unorthodox debate prep k...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  type\n",
       "11690   rwanda philippine rate well uk gender equalit...   1.0\n",
       "16702   climate change opinion susan goldberg editor ...   0.0\n",
       "19393   inside bernie sander unorthodox debate prep k...   0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los textos y las targets variables a listas\n",
    "texts = list(df['text'])\n",
    "targets = list(df['type'])\n",
    "\n",
    "# División en conjunto de entrenamiento y test\n",
    "x_train, y_train, x_test, y_test = nlp_f.train_test_split(texts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el diccionario (vocabulario)\n",
    "tokenizer = tf_tokenizer(num_words = 20000, oov_token = '<null_token>', lower = False, char_level = False)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_dict = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los textos en secuencias\n",
    "x_train_sequence = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_sequence = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paddeamos las secuencias\n",
    "train_padded = pad_sequences(x_train_sequence, maxlen = 600, dtype = 'int32', truncating = 'post', padding = 'post')\n",
    "test_padded = pad_sequences(x_test_sequence, maxlen = 600, dtype = 'int32', truncating = 'post', padding = 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cargamos la extensión de TB para notebooks\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Limpiar logs de ejecuciones anteriores \n",
    "# (necesario ejecutar conda install posix en Anaconda prompt para poder ejecutarlo en Windows 10)\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de los hiperparámetros \n",
    "Listamos los hiperparámetros a optimizar y sus valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el plugin HParams de Tensorboard\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# Listamos los parámetros a optimizar y sus distintos valores\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2, 0.4))\n",
    "HP_LR = hp.HParam('learning_rate', hp.Discrete([0.001, 0.01, 0.05]))\n",
    "HP_BATCH = hp.HParam('batch_size', hp.Discrete([50, 100, 200]))\n",
    "HP_LSTM = hp.HParam('lstm_units', hp.Discrete([128, 256]))\n",
    "\n",
    "METRIC_F1 = 'f1-score'    #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams = [HP_DROPOUT, HP_LR, HP_BATCH, HP_LSTM],\n",
    "    metrics = [hp.Metric(METRIC_F1, display_name = 'F1-Score')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo\n",
    "Definimos una función que entrene a la red neuronal recurrente definida durante el sprint 3 con unos parámetros determinados, el modelo devolverá el valor de f1-score en el conjunto de test una vez finalizado el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_rnn(hparams):\n",
    "    # ----Comenzamos definiendo el modelo\n",
    "    model = tf.keras.Sequential()\n",
    "    # Capa de Embedding\n",
    "    model.add(tf.keras.layers.Embedding(input_dim = 20000, # Tamaño del vocabulario\n",
    "                                       output_dim = 100, # Número de dimensiones de WE\n",
    "                                       embeddings_initializer = 'uniform',\n",
    "                                       mask_zero = True))\n",
    "    # Capa bidireccional\n",
    "    model.add(tf.keras.layers.Bidirectional(\n",
    "        # Capa LSTM\n",
    "        tf.keras.layers.LSTM(units = hparams[HP_LSTM],   # Hiperparámetro a optimizar\n",
    "                            activation = 'tanh',\n",
    "                            recurrent_activation = 'sigmoid',\n",
    "                            use_bias = True,\n",
    "                            dropout = hparams[HP_DROPOUT],   # Hiperparámetro a optimizar\n",
    "                            recurrent_dropout = 0.05)))\n",
    "    # Capa densa 1\n",
    "    model.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
    "    \n",
    "    # Capa Dropout 1\n",
    "    model.add(tf.keras.layers.Dropout(rate = hparams[HP_DROPOUT]))  # Hiperparámetro a optimizar\n",
    "    \n",
    "    # Capa densa 2\n",
    "    model.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))\n",
    "    \n",
    "    # Capa Dropout 2\n",
    "    model.add(tf.keras.layers.Dropout(rate = hparams[HP_DROPOUT]))  # Hiperparámetro a optimizar\n",
    "    \n",
    "    # Capa de salida\n",
    "    model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "    \n",
    "    # Definimos el optimizador\n",
    "    rmsprop_optim = tf.keras.optimizers.RMSprop(learning_rate = hparams[HP_LR])  # Hiperparámetro a optimizar\n",
    "    \n",
    "    # ----Compilamos el modelo\n",
    "    model.compile(optimizer= rmsprop_optim, loss = 'binary_crossentropy',\n",
    "                 metrics = ['accuracy', 'Precision', 'Recall', nlp_f.f1_score])\n",
    "    \n",
    "    # ----Entrenar el modelo (No es necesario llamar a tensorboard)\n",
    "    model.fit(train_padded, np.array(y_train), epochs = 3,\n",
    "             batch_size = hparams[HP_BATCH])    # Hiperparámetro a optimizar\n",
    "    \n",
    "    # ----Evaluar el conjunto de pruebas\n",
    "    # loss, acc, pre, rec, f1\n",
    "    _, _, _, _, f1 = model.evaluate(test_padded, np.array(y_test))\n",
    "    \n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las ejecuciones, para cada ejecución guardamos los hiperparámetros utilizados y el resultado obtenido en el log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)   # Almacenar los valores de los parámetros usados\n",
    "        f1 = train_test_rnn(hparams)  # Entrenamos el modelo con los valores especificados\n",
    "        \n",
    "        tf.summary.scalar(METRIC_F1, f1, step = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecuciones\n",
    "Realizamos el entrenamiento con todos los valores de los hiperparámetros y guardamos los logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Iniciando ejecución : run-0\n",
      "{'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 50, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 944s 69ms/sample - loss: 0.2517 - accuracy: 0.8973 - Precision: 0.8928 - Recall: 0.9358 - f1_score: 0.9163\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 922s 68ms/sample - loss: 0.0832 - accuracy: 0.9732 - Precision: 0.9760 - Recall: 0.9780 - f1_score: 0.9768\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 925s 68ms/sample - loss: 0.0498 - accuracy: 0.9862 - Precision: 0.9894 - Recall: 0.9870 - f1_score: 0.9878\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1185 - accuracy: 0.9580 - Precision: 0.9624 - Recall: 0.9666 - f1_score: 0.9645\n",
      "--Iniciando ejecución : run-1\n",
      "{'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 100, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 557s 41ms/sample - loss: 0.3095 - accuracy: 0.8856 - Precision: 0.8765 - Recall: 0.9350 - f1_score: 0.9087\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 551s 41ms/sample - loss: 0.0867 - accuracy: 0.9704 - Precision: 0.9759 - Recall: 0.9731 - f1_score: 0.9742\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 553s 41ms/sample - loss: 0.0382 - accuracy: 0.9875 - Precision: 0.9900 - Recall: 0.9885 - f1_score: 0.9892\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1282 - accuracy: 0.9578 - Precision: 0.9581 - Recall: 0.9709 - f1_score: 0.9644\n",
      "--Iniciando ejecución : run-2\n",
      "{'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 200, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 412s 30ms/sample - loss: 0.3757 - accuracy: 0.8565 - Precision: 0.8410 - Recall: 0.9289 - f1_score: 0.8870\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 402s 30ms/sample - loss: 0.1238 - accuracy: 0.9673 - Precision: 0.9737 - Recall: 0.9700 - f1_score: 0.9720\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 405s 30ms/sample - loss: 0.0407 - accuracy: 0.9877 - Precision: 0.9906 - Recall: 0.9882 - f1_score: 0.9895\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1961 - accuracy: 0.9401 - Precision: 0.9197 - Recall: 0.9846 - f1_score: 0.9508\n",
      "--Iniciando ejecución : run-3\n",
      "{'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 50, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 942s 69ms/sample - loss: 0.4974 - accuracy: 0.7777 - Precision: 0.7647 - Recall: 0.8925 - f1_score: 0.8198\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 936s 69ms/sample - loss: 0.1901 - accuracy: 0.9373 - Precision: 0.9404 - Recall: 0.9526 - f1_score: 0.9450\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 937s 69ms/sample - loss: 0.1051 - accuracy: 0.9698 - Precision: 0.9732 - Recall: 0.9748 - f1_score: 0.9735\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1534 - accuracy: 0.9590 - Precision: 0.9541 - Recall: 0.9776 - f1_score: 0.9658\n",
      "--Iniciando ejecución : run-4\n",
      "{'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 100, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 564s 41ms/sample - loss: 0.5808 - accuracy: 0.7212 - Precision: 0.7228 - Recall: 0.8446 - f1_score: 0.7602\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 559s 41ms/sample - loss: 0.2982 - accuracy: 0.8911 - Precision: 0.8981 - Recall: 0.9167 - f1_score: 0.9057\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 559s 41ms/sample - loss: 0.1370 - accuracy: 0.9569 - Precision: 0.9613 - Recall: 0.9647 - f1_score: 0.9624\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1979 - accuracy: 0.9458 - Precision: 0.9408 - Recall: 0.9692 - f1_score: 0.9546\n",
      "--Iniciando ejecución : run-5\n",
      "{'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 200, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 401s 30ms/sample - loss: 0.5736 - accuracy: 0.7855 - Precision: 0.7955 - Recall: 0.8496 - f1_score: 0.8093\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 395s 29ms/sample - loss: 0.2368 - accuracy: 0.9288 - Precision: 0.9339 - Recall: 0.9445 - f1_score: 0.9355\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 395s 29ms/sample - loss: 0.0881 - accuracy: 0.9706 - Precision: 0.9735 - Recall: 0.9760 - f1_score: 0.9743\n",
      "5827/5827 [==============================] - 69s 12ms/sample - loss: 0.1736 - accuracy: 0.9355 - Precision: 0.9511 - Recall: 0.9390 - f1_score: 0.9439\n",
      "--Iniciando ejecución : run-6\n",
      "{'dropout': 0.2, 'learning_rate': 0.05, 'batch_size': 50, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 944s 69ms/sample - loss: 1.4273 - accuracy: 0.5673 - Precision: 0.5820 - Recall: 0.9083 - f1_score: 0.6917\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 937s 69ms/sample - loss: 0.7204 - accuracy: 0.5966 - Precision: 0.5968 - Recall: 0.9446 - f1_score: 0.7247\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 936s 69ms/sample - loss: 0.7343 - accuracy: 0.5802 - Precision: 0.5814 - Recall: 0.9934 - f1_score: 0.7308\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.6783 - accuracy: 0.5907 - Precision: 0.5907 - Recall: 1.0000 - f1_score: 0.7394\n",
      "--Iniciando ejecución : run-7\n",
      "{'dropout': 0.2, 'learning_rate': 0.05, 'batch_size': 100, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 566s 42ms/sample - loss: 1.5596 - accuracy: 0.5744 - Precision: 0.5813 - Recall: 0.9588 - f1_score: 0.7119\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 561s 41ms/sample - loss: 0.8884 - accuracy: 0.6207 - Precision: 0.6281 - Recall: 0.8527 - f1_score: 0.7021\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 562s 41ms/sample - loss: 0.5231 - accuracy: 0.8152 - Precision: 0.7986 - Recall: 0.9124 - f1_score: 0.8492\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.3579 - accuracy: 0.7968 - Precision: 0.7447 - Recall: 0.9983 - f1_score: 0.8511\n",
      "--Iniciando ejecución : run-8\n",
      "{'dropout': 0.2, 'learning_rate': 0.05, 'batch_size': 200, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 401s 29ms/sample - loss: 2.0644 - accuracy: 0.5664 - Precision: 0.5800 - Recall: 0.9223 - f1_score: 0.6897\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 394s 29ms/sample - loss: 0.6966 - accuracy: 0.5741 - Precision: 0.5813 - Recall: 0.9574 - f1_score: 0.7177\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 397s 29ms/sample - loss: 0.7008 - accuracy: 0.5747 - Precision: 0.5810 - Recall: 0.9636 - f1_score: 0.7212\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.6765 - accuracy: 0.5905 - Precision: 0.5906 - Recall: 0.9997 - f1_score: 0.7392\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "dropout_rate = HP_DROPOUT.domain.min_value\n",
    "lstm_u = HP_LSTM.domain.values[0]\n",
    "\n",
    "for learning_rate in HP_LR.domain.values:\n",
    "    for batch_size in HP_BATCH.domain.values:\n",
    "        hparams = {\n",
    "            HP_DROPOUT: dropout_rate,\n",
    "            HP_LR: learning_rate,\n",
    "            HP_BATCH: batch_size,\n",
    "            HP_LSTM: lstm_u\n",
    "        }\n",
    "                \n",
    "        run_name = 'run-%d' % session_num\n",
    "        print('--Iniciando ejecución : %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Iniciando ejecución : run-9\n",
      "{'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 50, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1594s 117ms/sample - loss: 0.2870 - accuracy: 0.8948 - Precision: 0.8965 - Recall: 0.9260 - f1_score: 0.9101\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1587s 117ms/sample - loss: 0.1101 - accuracy: 0.9650 - Precision: 0.9705 - Recall: 0.9693 - f1_score: 0.9688\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1592s 117ms/sample - loss: 0.0643 - accuracy: 0.9824 - Precision: 0.9859 - Recall: 0.9838 - f1_score: 0.9845\n",
      "5827/5827 [==============================] - 140s 24ms/sample - loss: 0.1175 - accuracy: 0.9610 - Precision: 0.9629 - Recall: 0.9715 - f1_score: 0.9670\n",
      "--Iniciando ejecución : run-10\n",
      "{'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 100, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1033s 76ms/sample - loss: 0.3628 - accuracy: 0.8686 - Precision: 0.8609 - Recall: 0.9231 - f1_score: 0.8930\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1134s 83ms/sample - loss: 0.1142 - accuracy: 0.9643 - Precision: 0.9720 - Recall: 0.9665 - f1_score: 0.9681\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1141s 84ms/sample - loss: 0.0789 - accuracy: 0.9799 - Precision: 0.9838 - Recall: 0.9817 - f1_score: 0.9826\n",
      "5827/5827 [==============================] - 148s 25ms/sample - loss: 0.1289 - accuracy: 0.9537 - Precision: 0.9640 - Recall: 0.9573 - f1_score: 0.9600\n",
      "--Iniciando ejecución : run-11\n",
      "{'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 200, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 812s 60ms/sample - loss: 0.4589 - accuracy: 0.8239 - Precision: 0.8102 - Recall: 0.9106 - f1_score: 0.8612\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 788s 58ms/sample - loss: 0.1511 - accuracy: 0.9535 - Precision: 0.9597 - Recall: 0.9604 - f1_score: 0.9597\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 738s 54ms/sample - loss: 0.0677 - accuracy: 0.9800 - Precision: 0.9844 - Recall: 0.9812 - f1_score: 0.9821\n",
      "5827/5827 [==============================] - 140s 24ms/sample - loss: 0.1465 - accuracy: 0.9497 - Precision: 0.9502 - Recall: 0.9654 - f1_score: 0.9574\n",
      "--Iniciando ejecución : run-12\n",
      "{'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 50, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1612s 119ms/sample - loss: 0.6333 - accuracy: 0.7018 - Precision: 0.6962 - Recall: 0.8646 - f1_score: 0.7617\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1609s 118ms/sample - loss: 0.2283 - accuracy: 0.9213 - Precision: 0.9224 - Recall: 0.9441 - f1_score: 0.9315\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1674s 123ms/sample - loss: 0.1269 - accuracy: 0.9629 - Precision: 0.9666 - Recall: 0.9698 - f1_score: 0.9670\n",
      "5827/5827 [==============================] - 152s 26ms/sample - loss: 0.1841 - accuracy: 0.9351 - Precision: 0.9836 - Recall: 0.9053 - f1_score: 0.9417\n",
      "--Iniciando ejecución : run-13\n",
      "{'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 100, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1135s 83ms/sample - loss: 0.7917 - accuracy: 0.5599 - Precision: 0.5845 - Recall: 0.8413 - f1_score: 0.6667\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1094s 80ms/sample - loss: 0.7106 - accuracy: 0.5775 - Precision: 0.5824 - Recall: 0.9669 - f1_score: 0.7249\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1129s 83ms/sample - loss: 0.5443 - accuracy: 0.7334 - Precision: 0.7153 - Recall: 0.8995 - f1_score: 0.7961\n",
      "5827/5827 [==============================] - 142s 24ms/sample - loss: 0.4768 - accuracy: 0.7929 - Precision: 0.7426 - Recall: 0.9939 - f1_score: 0.8481\n",
      "--Iniciando ejecución : run-14\n",
      "{'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 200, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 802s 59ms/sample - loss: 0.8340 - accuracy: 0.5757 - Precision: 0.5941 - Recall: 0.8537 - f1_score: 0.6849\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 778s 57ms/sample - loss: 0.6921 - accuracy: 0.5988 - Precision: 0.5961 - Recall: 0.9617 - f1_score: 0.7344\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 756s 56ms/sample - loss: 0.6899 - accuracy: 0.6444 - Precision: 0.6291 - Recall: 0.9469 - f1_score: 0.7467\n",
      "5827/5827 [==============================] - 147s 25ms/sample - loss: 0.6160 - accuracy: 0.6614 - Precision: 0.6363 - Recall: 0.9962 - f1_score: 0.7745\n",
      "--Iniciando ejecución : run-15\n",
      "{'dropout': 0.2, 'learning_rate': 0.05, 'batch_size': 50, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1688s 124ms/sample - loss: 1.6450 - accuracy: 0.5627 - Precision: 0.5798 - Recall: 0.9011 - f1_score: 0.6810\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1687s 124ms/sample - loss: 0.9805 - accuracy: 0.5710 - Precision: 0.5798 - Recall: 0.9524 - f1_score: 0.7135\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1649s 121ms/sample - loss: 0.7025 - accuracy: 0.5810 - Precision: 0.5814 - Recall: 0.9985 - f1_score: 0.7327\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.6853 - accuracy: 0.5907 - Precision: 0.5907 - Recall: 1.0000 - f1_score: 0.7394\n",
      "--Iniciando ejecución : run-16\n",
      "{'dropout': 0.2, 'learning_rate': 0.05, 'batch_size': 100, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1010s 74ms/sample - loss: 1.4017 - accuracy: 0.5743 - Precision: 0.5822 - Recall: 0.9494 - f1_score: 0.7085\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1004s 74ms/sample - loss: 0.9695 - accuracy: 0.5752 - Precision: 0.5802 - Recall: 0.9750 - f1_score: 0.7229\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1006s 74ms/sample - loss: 1.4424 - accuracy: 0.5621 - Precision: 0.5827 - Recall: 0.8705 - f1_score: 0.6731\n",
      "5827/5827 [==============================] - 138s 24ms/sample - loss: 0.6764 - accuracy: 0.5905 - Precision: 0.5906 - Recall: 0.9997 - f1_score: 0.7392\n",
      "--Iniciando ejecución : run-17\n",
      "{'dropout': 0.2, 'learning_rate': 0.05, 'batch_size': 200, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 713s 52ms/sample - loss: 1.7322 - accuracy: 0.5670 - Precision: 0.5804 - Recall: 0.9225 - f1_score: 0.6958\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 704s 52ms/sample - loss: 0.7885 - accuracy: 0.5680 - Precision: 0.5811 - Recall: 0.9210 - f1_score: 0.6990\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 704s 52ms/sample - loss: 0.8599 - accuracy: 0.5700 - Precision: 0.5795 - Recall: 0.9497 - f1_score: 0.7108\n",
      "5827/5827 [==============================] - 142s 24ms/sample - loss: 0.6718 - accuracy: 0.5905 - Precision: 0.5906 - Recall: 0.9997 - f1_score: 0.7392\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = HP_DROPOUT.domain.min_value\n",
    "lstm_u = HP_LSTM.domain.values[1]\n",
    "\n",
    "for learning_rate in HP_LR.domain.values:\n",
    "    for batch_size in HP_BATCH.domain.values:\n",
    "        hparams = {\n",
    "            HP_DROPOUT: dropout_rate,\n",
    "            HP_LR: learning_rate,\n",
    "            HP_BATCH: batch_size,\n",
    "            HP_LSTM: lstm_u\n",
    "        }\n",
    "                \n",
    "        run_name = 'run-%d' % session_num\n",
    "        print('--Iniciando ejecución : %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Iniciando ejecución : run-18\n",
      "{'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 50, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 943s 69ms/sample - loss: 0.2862 - accuracy: 0.8937 - Precision: 0.8841 - Recall: 0.9406 - f1_score: 0.9137\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 935s 69ms/sample - loss: 0.0936 - accuracy: 0.9668 - Precision: 0.9737 - Recall: 0.9691 - f1_score: 0.9712\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 941s 69ms/sample - loss: 0.0499 - accuracy: 0.9827 - Precision: 0.9857 - Recall: 0.9846 - f1_score: 0.9845\n",
      "5827/5827 [==============================] - 71s 12ms/sample - loss: 0.1292 - accuracy: 0.9580 - Precision: 0.9686 - Recall: 0.9599 - f1_score: 0.9642\n",
      "--Iniciando ejecución : run-19\n",
      "{'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 100, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 564s 41ms/sample - loss: 0.3288 - accuracy: 0.8685 - Precision: 0.8588 - Recall: 0.9261 - f1_score: 0.8954\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 557s 41ms/sample - loss: 0.0996 - accuracy: 0.9668 - Precision: 0.9739 - Recall: 0.9689 - f1_score: 0.9710\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 558s 41ms/sample - loss: 0.0516 - accuracy: 0.9831 - Precision: 0.9872 - Recall: 0.9837 - f1_score: 0.9853\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1318 - accuracy: 0.9564 - Precision: 0.9523 - Recall: 0.9750 - f1_score: 0.9633\n",
      "--Iniciando ejecución : run-20\n",
      "{'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 200, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 413s 30ms/sample - loss: 0.5123 - accuracy: 0.8033 - Precision: 0.8005 - Recall: 0.8815 - f1_score: 0.8380\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 407s 30ms/sample - loss: 0.2365 - accuracy: 0.9149 - Precision: 0.9271 - Recall: 0.9265 - f1_score: 0.9263\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 407s 30ms/sample - loss: 0.1016 - accuracy: 0.9645 - Precision: 0.9702 - Recall: 0.9686 - f1_score: 0.9693\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1312 - accuracy: 0.9487 - Precision: 0.9662 - Recall: 0.9463 - f1_score: 0.9557\n",
      "--Iniciando ejecución : run-21\n",
      "{'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 50, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 943s 69ms/sample - loss: 0.5608 - accuracy: 0.6989 - Precision: 0.6889 - Recall: 0.8793 - f1_score: 0.7705\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 938s 69ms/sample - loss: 0.2483 - accuracy: 0.9200 - Precision: 0.9178 - Recall: 0.9473 - f1_score: 0.9308\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 937s 69ms/sample - loss: 0.1184 - accuracy: 0.9654 - Precision: 0.9670 - Recall: 0.9737 - f1_score: 0.9697\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.2673 - accuracy: 0.9444 - Precision: 0.9785 - Recall: 0.9262 - f1_score: 0.9508\n",
      "--Iniciando ejecución : run-22\n",
      "{'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 100, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 568s 42ms/sample - loss: 0.6973 - accuracy: 0.5905 - Precision: 0.6082 - Recall: 0.8317 - f1_score: 0.6885\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 564s 42ms/sample - loss: 0.4129 - accuracy: 0.8238 - Precision: 0.8202 - Recall: 0.8928 - f1_score: 0.8529\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 567s 42ms/sample - loss: 0.2726 - accuracy: 0.8948 - Precision: 0.8937 - Recall: 0.9297 - f1_score: 0.9115\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.2467 - accuracy: 0.9123 - Precision: 0.8934 - Recall: 0.9669 - f1_score: 0.9281\n",
      "--Iniciando ejecución : run-23\n",
      "{'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 200, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 401s 29ms/sample - loss: 0.6594 - accuracy: 0.6578 - Precision: 0.6830 - Recall: 0.7681 - f1_score: 0.7014\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 397s 29ms/sample - loss: 0.2780 - accuracy: 0.8987 - Precision: 0.9069 - Recall: 0.9203 - f1_score: 0.9123\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 394s 29ms/sample - loss: 0.1291 - accuracy: 0.9555 - Precision: 0.9612 - Recall: 0.9623 - f1_score: 0.9617\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.1553 - accuracy: 0.9406 - Precision: 0.9599 - Recall: 0.9387 - f1_score: 0.9485\n",
      "--Iniciando ejecución : run-24\n",
      "{'dropout': 0.4, 'learning_rate': 0.05, 'batch_size': 50, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 943s 69ms/sample - loss: 1.6859 - accuracy: 0.5727 - Precision: 0.5813 - Recall: 0.9483 - f1_score: 0.7096\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 938s 69ms/sample - loss: 0.7126 - accuracy: 0.5814 - Precision: 0.5819 - Recall: 0.9957 - f1_score: 0.7320\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 945s 69ms/sample - loss: 0.7050 - accuracy: 0.5811 - Precision: 0.5814 - Recall: 0.9992 - f1_score: 0.7325\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.6795 - accuracy: 0.5907 - Precision: 0.5907 - Recall: 1.0000 - f1_score: 0.7394\n",
      "--Iniciando ejecución : run-25\n",
      "{'dropout': 0.4, 'learning_rate': 0.05, 'batch_size': 100, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 571s 42ms/sample - loss: 1.3695 - accuracy: 0.5747 - Precision: 0.5813 - Recall: 0.9608 - f1_score: 0.7132\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 564s 42ms/sample - loss: 0.9123 - accuracy: 0.5704 - Precision: 0.5832 - Recall: 0.9158 - f1_score: 0.7005\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 567s 42ms/sample - loss: 0.6045 - accuracy: 0.7057 - Precision: 0.6960 - Recall: 0.8771 - f1_score: 0.7723\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.4935 - accuracy: 0.6871 - Precision: 0.6542 - Recall: 0.9980 - f1_score: 0.7881\n",
      "--Iniciando ejecución : run-26\n",
      "{'dropout': 0.4, 'learning_rate': 0.05, 'batch_size': 200, 'lstm_units': 128}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 400s 29ms/sample - loss: 2.5029 - accuracy: 0.5651 - Precision: 0.5808 - Recall: 0.9060 - f1_score: 0.6858\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 393s 29ms/sample - loss: 0.7623 - accuracy: 0.5769 - Precision: 0.5805 - Recall: 0.9822 - f1_score: 0.7283\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 396s 29ms/sample - loss: 0.8301 - accuracy: 0.5733 - Precision: 0.5804 - Recall: 0.9613 - f1_score: 0.7205\n",
      "5827/5827 [==============================] - 70s 12ms/sample - loss: 0.6742 - accuracy: 0.5907 - Precision: 0.5907 - Recall: 1.0000 - f1_score: 0.7394\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = HP_DROPOUT.domain.max_value\n",
    "lstm_u = HP_LSTM.domain.values[0]\n",
    "\n",
    "for learning_rate in HP_LR.domain.values:\n",
    "    for batch_size in HP_BATCH.domain.values:\n",
    "        hparams = {\n",
    "            HP_DROPOUT: dropout_rate,\n",
    "            HP_LR: learning_rate,\n",
    "            HP_BATCH: batch_size,\n",
    "            HP_LSTM: lstm_u\n",
    "        }\n",
    "                \n",
    "        run_name = 'run-%d' % session_num\n",
    "        print('--Iniciando ejecución : %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Iniciando ejecución : run-27\n",
      "{'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 50, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1622s 119ms/sample - loss: 0.2937 - accuracy: 0.8881 - Precision: 0.8808 - Recall: 0.9340 - f1_score: 0.9074\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1619s 119ms/sample - loss: 0.1357 - accuracy: 0.9625 - Precision: 0.9691 - Recall: 0.9664 - f1_score: 0.9664\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1618s 119ms/sample - loss: 0.0824 - accuracy: 0.9776 - Precision: 0.9829 - Recall: 0.9786 - f1_score: 0.9804\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.1672 - accuracy: 0.9530 - Precision: 0.9714 - Recall: 0.9483 - f1_score: 0.9590\n",
      "--Iniciando ejecución : run-28\n",
      "{'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 100, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1027s 76ms/sample - loss: 0.4286 - accuracy: 0.8377 - Precision: 0.8321 - Recall: 0.9031 - f1_score: 0.8678\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1031s 76ms/sample - loss: 0.1220 - accuracy: 0.9563 - Precision: 0.9642 - Recall: 0.9605 - f1_score: 0.9618\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1021s 75ms/sample - loss: 0.0672 - accuracy: 0.9774 - Precision: 0.9814 - Recall: 0.9798 - f1_score: 0.9804\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.1184 - accuracy: 0.9581 - Precision: 0.9728 - Recall: 0.9558 - f1_score: 0.9638\n",
      "--Iniciando ejecución : run-29\n",
      "{'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 200, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 722s 53ms/sample - loss: 0.5799 - accuracy: 0.7635 - Precision: 0.7626 - Recall: 0.8615 - f1_score: 0.8064\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 714s 53ms/sample - loss: 0.2175 - accuracy: 0.9187 - Precision: 0.9340 - Recall: 0.9255 - f1_score: 0.9270\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 718s 53ms/sample - loss: 0.2751 - accuracy: 0.9432 - Precision: 0.9493 - Recall: 0.9533 - f1_score: 0.9518\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.1423 - accuracy: 0.9525 - Precision: 0.9533 - Recall: 0.9669 - f1_score: 0.9597\n",
      "--Iniciando ejecución : run-30\n",
      "{'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 50, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1617s 119ms/sample - loss: 0.6103 - accuracy: 0.6884 - Precision: 0.6791 - Recall: 0.8799 - f1_score: 0.7608\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1614s 119ms/sample - loss: 0.2440 - accuracy: 0.9218 - Precision: 0.9275 - Recall: 0.9389 - f1_score: 0.9318\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1617s 119ms/sample - loss: 0.1237 - accuracy: 0.9630 - Precision: 0.9671 - Recall: 0.9694 - f1_score: 0.9677\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.1780 - accuracy: 0.9559 - Precision: 0.9420 - Recall: 0.9861 - f1_score: 0.9627\n",
      "--Iniciando ejecución : run-31\n",
      "{'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 100, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1020s 75ms/sample - loss: 0.7522 - accuracy: 0.5719 - Precision: 0.5928 - Recall: 0.8424 - f1_score: 0.6772\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1017s 75ms/sample - loss: 0.3990 - accuracy: 0.8429 - Precision: 0.8230 - Recall: 0.9298 - f1_score: 0.8754\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1017s 75ms/sample - loss: 0.1664 - accuracy: 0.9436 - Precision: 0.9439 - Recall: 0.9600 - f1_score: 0.9515\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.1536 - accuracy: 0.9477 - Precision: 0.9550 - Recall: 0.9564 - f1_score: 0.9553\n",
      "--Iniciando ejecución : run-32\n",
      "{'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 200, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 721s 53ms/sample - loss: 0.7733 - accuracy: 0.5616 - Precision: 0.5880 - Recall: 0.8227 - f1_score: 0.6644\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 714s 53ms/sample - loss: 0.6467 - accuracy: 0.6189 - Precision: 0.6150 - Recall: 0.9221 - f1_score: 0.7344\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 717s 53ms/sample - loss: 0.5507 - accuracy: 0.7554 - Precision: 0.7486 - Recall: 0.8724 - f1_score: 0.7964\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.3915 - accuracy: 0.8340 - Precision: 0.7842 - Recall: 0.9922 - f1_score: 0.8743\n",
      "--Iniciando ejecución : run-33\n",
      "{'dropout': 0.4, 'learning_rate': 0.05, 'batch_size': 50, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1611s 118ms/sample - loss: 1.9956 - accuracy: 0.5704 - Precision: 0.5801 - Recall: 0.9460 - f1_score: 0.7110\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1607s 118ms/sample - loss: 0.7500 - accuracy: 0.5794 - Precision: 0.5814 - Recall: 0.9889 - f1_score: 0.7293\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1611s 118ms/sample - loss: 0.8189 - accuracy: 0.5793 - Precision: 0.5821 - Recall: 0.9803 - f1_score: 0.7275\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.6763 - accuracy: 0.5907 - Precision: 0.5907 - Recall: 1.0000 - f1_score: 0.7394\n",
      "--Iniciando ejecución : run-34\n",
      "{'dropout': 0.4, 'learning_rate': 0.05, 'batch_size': 100, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 1067s 78ms/sample - loss: 2.4271 - accuracy: 0.5683 - Precision: 0.5800 - Recall: 0.9340 - f1_score: 0.7031\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 1008s 74ms/sample - loss: 0.8637 - accuracy: 0.5764 - Precision: 0.5814 - Recall: 0.9703 - f1_score: 0.7225\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 1006s 74ms/sample - loss: 1.4128 - accuracy: 0.5691 - Precision: 0.5795 - Recall: 0.9445 - f1_score: 0.7122\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.7407 - accuracy: 0.5907 - Precision: 0.5907 - Recall: 1.0000 - f1_score: 0.7394\n",
      "--Iniciando ejecución : run-35\n",
      "{'dropout': 0.4, 'learning_rate': 0.05, 'batch_size': 200, 'lstm_units': 256}\n",
      "Train on 13596 samples\n",
      "Epoch 1/3\n",
      "13596/13596 [==============================] - 740s 54ms/sample - loss: 3.8519 - accuracy: 0.5652 - Precision: 0.5835 - Recall: 0.8819 - f1_score: 0.6810\n",
      "Epoch 2/3\n",
      "13596/13596 [==============================] - 726s 53ms/sample - loss: 0.7517 - accuracy: 0.5778 - Precision: 0.5814 - Recall: 0.9790 - f1_score: 0.7281\n",
      "Epoch 3/3\n",
      "13596/13596 [==============================] - 722s 53ms/sample - loss: 0.8431 - accuracy: 0.5819 - Precision: 0.5822 - Recall: 0.9947 - f1_score: 0.7337\n",
      "5827/5827 [==============================] - 141s 24ms/sample - loss: 0.6767 - accuracy: 0.5907 - Precision: 0.5907 - Recall: 1.0000 - f1_score: 0.7394\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = HP_DROPOUT.domain.max_value\n",
    "lstm_u = HP_LSTM.domain.values[1]\n",
    "\n",
    "for learning_rate in HP_LR.domain.values:\n",
    "    for batch_size in HP_BATCH.domain.values:\n",
    "        hparams = {\n",
    "            HP_DROPOUT: dropout_rate,\n",
    "            HP_LR: learning_rate,\n",
    "            HP_BATCH: batch_size,\n",
    "            HP_LSTM: lstm_u\n",
    "        }\n",
    "                \n",
    "        run_name = 'run-%d' % session_num\n",
    "        print('--Iniciando ejecución : %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los resultados en TensorBoard\n",
    "Al cargar este notebook tras reiniciar el kernel, es bastante probable que TensorBoard no pueda visualizarse o que no se puede acceder a la página, para solucionarlo se recomienda reejecutar este notebook (poco recomendable por el coste en tiempo y computación) o utilizar el notebook \"Análisis de los logs.ipynb\" localizado en el mismo directorio que este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8364), started 0:01:01 ago. (Use '!kill 8364' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-814c94fef24e12e5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-814c94fef24e12e5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
